{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio\n",
        "!pip install ultralytics\n",
        "!pip install -U ray[tune]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wJN8101xVA06",
        "outputId": "56e32ac2-3408-4221-9fa6-93f0a288fc39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (5.8.0)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.115.6)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.4.0)\n",
            "Requirement already satisfied: gradio-client==1.5.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.1)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.26.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.11)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (11.0.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.9.2)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.19)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.8.1)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.41.3)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.13.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.32.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.5.1->gradio) (2024.10.0)\n",
            "Requirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.5.1->gradio) (14.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.16.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (4.66.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.23.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.2.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Collecting ultralytics\n",
            "  Using cached ultralytics-8.3.41-py3-none-any.whl.metadata (35 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.8.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (11.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.6)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Using cached ultralytics_thop-2.0.12-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Using cached ultralytics-8.3.41-py3-none-any.whl (899 kB)\n",
            "Using cached ultralytics_thop-2.0.12-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.41 ultralytics-thop-2.0.12\n",
            "Collecting ray[tune]\n",
            "  Using cached ray-2.40.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (17 kB)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (8.1.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (3.16.1)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (4.23.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (1.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (24.2)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (4.25.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (6.0.2)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (1.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (2.32.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (2.2.2)\n",
            "Collecting tensorboardX>=1.9 (from ray[tune])\n",
            "  Using cached tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: pyarrow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (17.0.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (2024.10.0)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.10/dist-packages (from pyarrow>=9.0.0->ray[tune]) (1.26.4)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[tune]) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[tune]) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[tune]) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[tune]) (0.21.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->ray[tune]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->ray[tune]) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->ray[tune]) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->ray[tune]) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ray[tune]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ray[tune]) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ray[tune]) (2024.8.30)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->ray[tune]) (1.16.0)\n",
            "Using cached tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "Using cached ray-2.40.0-cp310-cp310-manylinux2014_x86_64.whl (66.8 MB)\n",
            "Installing collected packages: tensorboardX, ray\n",
            "Successfully installed ray-2.40.0 tensorboardX-2.6.2.2\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'clear_output' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-c558daa8c021>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install ultralytics'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install -U ray[tune]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'clear_output' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKN6m4kNU_TF",
        "outputId": "f2b09e6a-1800-494e-d86d-bf4307908a1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from PIL import Image\n",
        "import re\n",
        "import numpy as np\n",
        "from IPython.display import display, Math, Latex\n",
        "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import os, sys\n",
        "\n",
        "# from PIL import Image\n",
        "# from torchvision import transforms\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# import sklearn as skl\n",
        "# import torch as t\n",
        "\n",
        "from ultralytics import YOLO\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import gradio as gr\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1r1v0No6BL9rcj_V8NH80V2jejREqud0E"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOwkYOEcVftN",
        "outputId": "285fe307-2346-478f-b7db-1f238615acfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1r1v0No6BL9rcj_V8NH80V2jejREqud0E\n",
            "From (redirected): https://drive.google.com/uc?id=1r1v0No6BL9rcj_V8NH80V2jejREqud0E&confirm=t&uuid=b324f2eb-4613-41f3-85f7-47cc829543e4\n",
            "To: /content/30_best.pt\n",
            "100% 52.1M/52.1M [00:01<00:00, 27.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1GS456miaCEOfG3Jqms2cH7V6ZYnhsVVR"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BkgjgzZV_1Q",
        "outputId": "e85dee6d-0f58-4cde-8ed5-40cfebd855ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1GS456miaCEOfG3Jqms2cH7V6ZYnhsVVR\n",
            "From (redirected): https://drive.google.com/uc?id=1GS456miaCEOfG3Jqms2cH7V6ZYnhsVVR&confirm=t&uuid=9dda9139-ca39-4dce-a0cf-2ede1743b345\n",
            "To: /content/trocr_version_2.gz\n",
            "100% 2.08G/2.08G [00:32<00:00, 64.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gunzip trocr_version_2.gz\n",
        "!tar -xvf trocr_version_2"
      ],
      "metadata": {
        "id": "tJc_i7JWWNz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j47e5Y7xU_TG"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucoCGRtcU_TH"
      },
      "source": [
        "# YOLO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rzTXtesOU_TI"
      },
      "outputs": [],
      "source": [
        "localize_model = YOLO(\"30_best.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RtqpMNPBU_TI"
      },
      "outputs": [],
      "source": [
        "def localize_image(image):\n",
        "\twith torch.no_grad():\n",
        "\t\tpredictions = localize_model.predict(\n",
        "\t\t\tsource=image,\n",
        "\t\t\tconf=0.1,\n",
        "\t\t\tiou=0.1,\n",
        "\t\t\tstream=True\n",
        "\t\t)\n",
        "\n",
        "\tfor prediction in predictions:\n",
        "\t\tif len(prediction.boxes.xyxy):\n",
        "\t\t\tboxes = prediction.boxes.xyxy.cpu().numpy()\n",
        "\t\t\tscores = prediction.boxes.conf.cpu().numpy()\n",
        "\n",
        "\t\t\t# print(boxes)\n",
        "\t\t\t# print(scores)\n",
        "\t\t\t# print(bbox)\n",
        "\t\t\tidx = np.argsort(scores)\n",
        "\t\t\tx1, y1, x2, y2 = boxes[idx[-1]]\n",
        "\n",
        "\t\t\tprint(boxes)\n",
        "\t\t\tresult = image.crop([x1, y1, x2, y2])\n",
        "\n",
        "\t\t\t# plt.imshow(result)\n",
        "\t\t\t# plt.axis('off')  # Hide the axis\n",
        "\t\t\t# plt.show()\n",
        "\n",
        "\t\t\treturn result\n",
        "\n",
        "\treturn image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAdJwEaDU_TI"
      },
      "source": [
        "# TrOCR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2uoE3lLU_TJ",
        "outputId": "37975cb2-b4c8-4412-bf36-47cb2c4cf0a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Config of the encoder: <class 'transformers.models.vit.modeling_vit.ViTModel'> is overwritten by shared encoder config: ViTConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.0,\n",
            "  \"encoder_stride\": 16,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.0,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"image_size\": 384,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"model_type\": \"vit\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_channels\": 3,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"patch_size\": 16,\n",
            "  \"qkv_bias\": false,\n",
            "  \"transformers_version\": \"4.46.2\"\n",
            "}\n",
            "\n",
            "Config of the decoder: <class 'transformers.models.trocr.modeling_trocr.TrOCRForCausalLM'> is overwritten by shared decoder config: TrOCRConfig {\n",
            "  \"activation_dropout\": 0.0,\n",
            "  \"activation_function\": \"gelu\",\n",
            "  \"add_cross_attention\": true,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"cross_attention_hidden_size\": 1024,\n",
            "  \"d_model\": 1024,\n",
            "  \"decoder_attention_heads\": 16,\n",
            "  \"decoder_ffn_dim\": 4096,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 12,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"dropout\": 0.1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_decoder\": true,\n",
            "  \"layernorm_embedding\": true,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"trocr\",\n",
            "  \"pad_token_id\": 1,\n",
            "  \"scale_embedding\": false,\n",
            "  \"transformers_version\": \"4.46.2\",\n",
            "  \"use_cache\": false,\n",
            "  \"use_learned_position_embeddings\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# path = \"/kaggle/input/latex-ocr-implementation/models/trocr-large-finetuned-math-captions\"\n",
        "\n",
        "path = './models/latexocr-finetuned'\n",
        "# path = 'microsoft/trocr-large-handwritten'\n",
        "processor = TrOCRProcessor.from_pretrained(path)\n",
        "model = VisionEncoderDecoderModel.from_pretrained(path).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emHdnEGuU_TJ"
      },
      "outputs": [],
      "source": [
        "def predict_ocr(image):\n",
        "\twith torch.no_grad():\n",
        "\t\tpixel_values = processor(images = image, return_tensors=\"pt\").pixel_values.to(device)\n",
        "\t\tout = model.generate(pixel_values, max_new_tokens = 256)\n",
        "\t\tpred = processor.decode(out[0], skip_special_tokens=True).replace(\"\\\\ \", \"\\\\\")\n",
        "\t\tsymbols = ['lim', 'sin', 'cos', 'tan']\n",
        "\t\tfor sym in symbols:\n",
        "\t\t\tpred = pred.replace(sym, f\"\\\\{sym}\")\n",
        "\t\tprint(pred)\n",
        "\treturn f'${pred}$'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4C8FZPCiU_TJ"
      },
      "source": [
        "## Ensemble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o1K0qzYUU_TK"
      },
      "outputs": [],
      "source": [
        "def predict_latex(image):\n",
        "\tprint('localizing image')\n",
        "\tcropped = localize_image(image)\n",
        "\tprint('done localizing')\n",
        "\tprint('predicting')\n",
        "\tprediction = predict_ocr(cropped)\n",
        "\tprint('done prediction')\n",
        "\n",
        "\treturn prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 796
        },
        "id": "6xIABE9kU_TK",
        "outputId": "6da15986-47d9-4d91-ba7d-c98a662560b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://ab26f010a740ced9b6.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://ab26f010a740ced9b6.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "localizing image\n",
            "\n",
            "0: 768x1024 1 formula, 69.9ms\n",
            "[[     370.23      401.74        1862      968.12]]\n",
            "done localizing\n",
            "predicting\n",
            "\\lim_{n\\rightarrow\\infty}\\left(\\frac{1}{n}+\\frac{1}{n+1}+\\frac{1}{n+2}\\right)\n",
            "done prediction\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://ab26f010a740ced9b6.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# Create Gradio interface\n",
        "with gr.Blocks() as demo:\n",
        "\tgr.Markdown(\"# Image to LaTeX Converter\")\n",
        "\tgr.Markdown(\"Upload an image containing a mathematical expression, and this tool will convert it to LaTeX.\")\n",
        "\n",
        "\twith gr.Row():\n",
        "\t\twith gr.Column():\n",
        "\t\t\timage_input = gr.Image(type=\"pil\", label=\"Upload Image\")\n",
        "\t\twith gr.Column():\n",
        "\t\t\tlatex_output = gr.Markdown(height=100, latex_delimiters=[ {\"left\": \"$\", \"right\": \"$\", \"display\": True }])\n",
        "\n",
        "\tconvert_button = gr.Button(\"Convert\")\n",
        "\n",
        "\tconvert_button.click(\n",
        "\t\tpredict_latex,\n",
        "\t\tinputs=image_input,\n",
        "\t\toutputs=latex_output\n",
        "\t)\n",
        "\n",
        "demo.launch(share=True, debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pv0JOvsFU_TL"
      },
      "outputs": [],
      "source": [
        "# This part is the implementation of augmentation\n",
        "import albumentations as A\n",
        "import cv2\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "\n",
        "def add_padding(image, top, bottom, left, right, color=(255, 255, 255)):\n",
        "\tpadded_image = cv2.copyMakeBorder(image, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)\n",
        "\treturn padded_image\n",
        "\n",
        "def create_notebook_background(image, line_color=(200, 200, 200), line_thickness=1, line_spacing=random.randint(100, 200)):\n",
        "\theight, width, _ = image.shape\n",
        "\tbackground = np.ones_like(image) * 255  # Create a white background\n",
        "\n",
        "\t# Draw vertical lines\n",
        "\tfor y in range(0, height, line_spacing):\n",
        "\t\tcv2.line(background, (0, y), (width, y), line_color, thickness=line_thickness)\n",
        "\n",
        "\treturn background\n",
        "\n",
        "def replace_white_pixel_with_background(image, background):\n",
        "\t# Find all white pixels in the image\n",
        "\twhite_pixels = np.all(image == [255, 255, 255], axis=-1)\n",
        "\n",
        "\t# Replace white pixels with the corresponding pixels from the background\n",
        "\timage[white_pixels] = background[white_pixels]\n",
        "\n",
        "\treturn image\n",
        "\n",
        "def apply_transformations(image):\n",
        "\ttransform = A.Compose([\n",
        "\t\tA.PlanckianJitter(temperature_limit=(5500, 9000) ,p=1),  # 10% chance to apply Planckian jitter\n",
        "\t\tA.Rotate(limit=(-10, 10), p=0.5),  # 50% chance to rotate the image\n",
        "\t\tA.Downscale(scale_min=0.5, scale_max=0.9, p=0.2),  # 20% chance to downscale the image\n",
        "\t\tA.OneOf([\n",
        "\t\t\tA.Blur(blur_limit=(3, 7), p=1),  # apply blur\n",
        "\t\t\tA.GlassBlur(sigma=0.8, max_delta=2, iterations=1, mode='fast', p=1),  # apply glass blur\n",
        "\t\t\tA.MedianBlur(blur_limit=(3,5), p=1),  # apply median blur\n",
        "\t\t\tA.Downscale(scale_min=0.5, scale_max=0.9, p=1), # downscale the image\n",
        "\t\t], p=1),  # 50% chance to apply one of the above blur augmentations\n",
        "\t\t\tA.RandomBrightnessContrast(brightness_limit=(-0.7,0.1), contrast_limit=(-0.2,0.7), p=1),  # 40% chance to adjust brightness and contrast\n",
        "\t\tA.OneOf([\n",
        "\t\t\tA.PlanckianJitter(temperature_limit=(5500, 9000), p=1),  # 10% chance to apply Planckian jitter\n",
        "\t\t\tA.RGBShift(r_shift_limit=20, g_shift_limit=20, b_shift_limit=20, p=1),  # 30% chance to shift the RGB channels\n",
        "\t\t], p=0.5),  # 50% chance to apply one of the above color augmentations\n",
        "\t\tA.Posterize(num_bits=4, p=0.3),  # 30% chance to apply posterization\n",
        "\t\tA.Sharpen(alpha=(0.1, 1), lightness=(1.0, 1.0), p=0.3),  # 30% chance to sharpen the image\n",
        "\t])\n",
        "\n",
        "\t# Apply the augmentations to the input image\n",
        "\taugmented = transform(image=image)\n",
        "\timage = augmented[\"image\"]\n",
        "\t# print(augmented['replay'])\n",
        "\n",
        "\treturn image\n",
        "\n",
        "def erode_and_dilate(image):\n",
        "\n",
        "\tpick = random.randint(0,1)\n",
        "\tif pick == 0:\n",
        "\t\tsize= random.randint(1,4)\n",
        "\t\tkernel = np.ones((size, size), np.uint8)\n",
        "\t\timage = cv2.erode(image, kernel, iterations=1)\n",
        "\t\t# image= cv2.dilate(image, kernel, iterations=1)\n",
        "\telse:\n",
        "\t\tsize= random.randint(1,2)\n",
        "\t\tkernel = np.ones((size, size), np.uint8)\n",
        "\t\t# image = cv2.erode(image, kernel, iterations=1)\n",
        "\t\timage= cv2.dilate(image, kernel, iterations=1)\n",
        "\n",
        "\treturn image\n",
        "\n",
        "def augment_image(image):\n",
        "\t# Read an example image\n",
        "\timage = cv2.imread(\"./converted_image.jpg\")\n",
        "\timage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
        "\t# Apply augmentations\n",
        "\timage = add_padding(image, 70, 70, 70, 70)\n",
        "\tif random.random() < 0.4:\n",
        "\t\tbackground = create_notebook_background(image)\n",
        "\t\timage = replace_white_pixel_with_background(image, background)\n",
        "\timage = augment_image(image)\n",
        "\timage = erode_and_dilate(image)\n",
        "\n",
        "\treturn image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ObO_byMwU_TL"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def crop_to_formula(image, padding = 30):\n",
        "\n",
        "\n",
        "\n",
        "\t# Image: 4 channel image with alpha.\n",
        "\t# Convert black pixels to white pixels.\n",
        "\tdata = np.array(image)\n",
        "\tred, green, blue, alpha = data.T\n",
        "\tblack_areas = (red < 10) & (blue < 10) & (green < 10)\n",
        "\t# Convert alpha to white.\n",
        "\tdata[..., -1] = 255\n",
        "\t# Crop a box around the area that contains black pixels.\n",
        "\tcoords = np.argwhere(black_areas)\n",
        "\tx0, y0 = coords.min(axis=0)\n",
        "\tx1, y1 = coords.max(axis=0) + 1\n",
        "\t# Add padding.\n",
        "\tx0 = max(0, x0 - padding)\n",
        "\ty0 = max(0, y0 - padding)\n",
        "\tx1 = min(image.width, x1 + padding)\n",
        "\ty1 = min(image.height, y1 + padding)\n",
        "\tprint(data[y0:y1,x0:x1].shape)\n",
        "\timage = Image.fromarray(data[y0:y1, x0:x1])\n",
        "\n",
        "\tif random.random() < 0.5:\n",
        "\t\timage = np.array(image)\n",
        "\t\timage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "\t\t# Apply augmentations\n",
        "\t\t# image = add_padding(image, 70, 70, 70, 70)\n",
        "\t\tbackground = create_notebook_background(image)\n",
        "\t\timage = replace_white_pixel_with_background(image, background)\n",
        "\t\timage = apply_transformations(image)\n",
        "\t\tif random.random() < 0.5:\n",
        "\t\t\timage = 255 - image\n",
        "\n",
        "\t\timage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\t\timage = Image.fromarray(image)\n",
        "\n",
        "\treturn image.convert('RGB')\n",
        "\n",
        "def renderedLaTeXLabelstr2Formula(label: str):\n",
        "\t# We're matching \\\\label{...whatever} and removing it\n",
        "\tlabel = label.replace(\"(\", r\"\\left(\")\n",
        "\tlabel = label.replace(\"[\", r\"\\left[\")\n",
        "\tlabel = label.replace(\"\\{\", r\"\\left\\{\")\n",
        "\tlabel = label.replace(\")\", r\"\\right)\")\n",
        "\tlabel = label.replace(\"]\", r\"\\right]\")\n",
        "\tlabel = label.replace(\"\\}\", r\"\\right\\}\")\n",
        "\t# label = re.sub(r\"\\\\label\\{[^\\}]*\\}\", \"\", label)\n",
        "\t# # We match \\, and remove it.\n",
        "\t# label = re.sub(r\"\\\\,\", \"\", label)\n",
        "\t# label = re.sub(r\"\\\\mbox\\s*\\{\\s*(.*?)\\s*\\}\", r\"\\1\", label)\n",
        "\t# if r\"\\begin\" in label:\n",
        "\t#\t label = re.sub(r\"&(\\d)\", r\"& \\1\", label)\n",
        "\t#\t label = re.sub(r\"\\\\(\\d)\", r\"\\\\ \\1\", label)\n",
        "\t#\t label = re.sub(r\"matrix}(.*?)\", r\"matrix} \\1\", label)\n",
        "\t#\t label = re.sub(r\"(\\d)\\\\\", r\"\\1 \\\\\", label)\n",
        "\treturn label\n",
        "\n",
        "def display_formula(latex: str):\n",
        "\t# Remove \\mbox{...} - not supported by the inline MathJax renderer\n",
        "\tparsed_latex = re.sub(r\"\\\\mbox\\{[^\\}]*\\}\", \"\", latex)\n",
        "\tdisplay(Math(parsed_latex))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2024-11-28T01:00:12.402893Z",
          "iopub.status.busy": "2024-11-28T01:00:12.402658Z",
          "iopub.status.idle": "2024-11-28T01:00:12.41959Z",
          "shell.execute_reply": "2024-11-28T01:00:12.41841Z",
          "shell.execute_reply.started": "2024-11-28T01:00:12.402869Z"
        },
        "id": "hFNknTkxU_TM"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class renderedLaTeXDataset(Dataset):\n",
        "\tdef __init__(self, image_folder, image_label_file, processor, device):\n",
        "\t\tself.image_folder = image_folder\n",
        "\t\twith open(image_label_file, 'r') as f:\n",
        "\t\t\tself.image_label = json.load(f)\n",
        "\t\tself.file_name = os.listdir(self.image_folder)\n",
        "\t\tself.device = device\n",
        "\t\tself.processor = processor\n",
        "\t\tself.num_image = len(self.image_label)\n",
        "\n",
        "\tdef __len__(self):\n",
        "\t\treturn self.num_image\n",
        "\n",
        "\tdef __getitem__(self, idx):\n",
        "\t\t# img_name = os.path.join(self.image_folder, self.file_name[idx])\n",
        "\t\tnum_folder = str(idx // 1000 + 1).zfill(3)\n",
        "\t\timg_name = os.path.join(self.image_folder, f\"folder_{num_folder}/{idx+1}.jpg\")\n",
        "\t\t# print(img_name)\n",
        "\t\timage = Image.open(img_name).convert('RGBA')\n",
        "\t\timage = crop_to_formula(image)\n",
        "\t\tdisplay(image)\n",
        "\n",
        "\n",
        "\t\tinputs = self.processor(images = image, padding = \"max_length\", return_tensors=\"pt\")\n",
        "\n",
        "\t\t# outside = np.array(inputs['pixel_values'])\n",
        "\t\t# print(outside)\n",
        "\t\t# display(Image.fromarray(outside))\n",
        "\t\t# display(Image.fromarray(np.array(inputs['pixel_values'].cpu())))\n",
        "\n",
        "\t\tfor key in inputs:\n",
        "\t\t\tinputs[key] = inputs[key].squeeze() # Get rid of batch dimension since the dataloader will batch it for us.\n",
        "\n",
        "\t\t# formula_idx = self.image_label[(self.file_name[idx]).split(\".\")[0]]\n",
        "\t\tformula_idx = self.image_label[str(idx+1)]\n",
        "\n",
        "\n",
        "\t\t# print(formula_idx)\n",
        "\n",
        "\t\tformula_idx = renderedLaTeXLabelstr2Formula(formula_idx)\n",
        "\t\tprint(formula_idx)\n",
        "\t\tdisplay(Math(formula_idx))\n",
        "\t\t# print(caption)\n",
        "\t\t# print(self.processor.tokenizer.tokenize(caption))\n",
        "\t\tcaption = self.processor.tokenizer.encode(\n",
        "\t\t\tformula_idx, return_tensors=\"pt\", padding = \"max_length\", max_length = 512, truncation = True, # Tweak this\n",
        "\t\t\t).to(self.device).squeeze()\n",
        "\t\tprint(inputs['pixel_values'].shape)\n",
        "\t\treturn inputs, caption\n",
        "\n",
        "def set_seed(seed):\n",
        "\tnp.random.seed(seed)\n",
        "\tt.manual_seed(seed)\n",
        "\tif t.cuda.is_available():\n",
        "\t\tt.cuda.manual_seed_all(seed)\n",
        "\tskl.utils.check_random_state(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-28T01:00:12.420886Z",
          "iopub.status.busy": "2024-11-28T01:00:12.420635Z",
          "iopub.status.idle": "2024-11-28T01:00:12.970573Z",
          "shell.execute_reply": "2024-11-28T01:00:12.969005Z",
          "shell.execute_reply.started": "2024-11-28T01:00:12.420847Z"
        },
        "id": "XkM-RWOOU_TM"
      },
      "outputs": [],
      "source": [
        "os.listdir('/kaggle/input/dataset-100k-images-trocr/train_splits/folder_001')[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-28T01:00:12.971276Z",
          "iopub.status.idle": "2024-11-28T01:00:12.971611Z",
          "shell.execute_reply": "2024-11-28T01:00:12.971475Z",
          "shell.execute_reply.started": "2024-11-28T01:00:12.971458Z"
        },
        "id": "23Sq7hYRU_TM"
      },
      "outputs": [],
      "source": [
        "NUM_EPOCHS = 5\n",
        "LEARNING_RATE = 1e-5\n",
        "BATCH_SIZE = 2 # 10 gigs of Vram -> 4, <5 gigs of vram -> 2\n",
        "SHUFFLE_DATASET = True\n",
        "\n",
        "set_seed(0)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "train_ds = renderedLaTeXDataset(image_folder='/kaggle/input/dataset-100k-images-trocr/train_splits',\n",
        "\t\t\t\t\t\t\t   image_label_file='/kaggle/input/dataset-100k-images-trocr/train_splits/labels.json',\n",
        "\t\t\t\t\t\t\t\tprocessor=processor,\n",
        "\t\t\t\t\t\t\t   device=device)\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size = BATCH_SIZE, shuffle = SHUFFLE_DATASET, num_workers = 0)\n",
        "model.config.decoder_start_token_id = processor.tokenizer.cls_token_id\n",
        "model.config.pad_token_id = processor.tokenizer.pad_token_id\n",
        "model.to(device)\n",
        "model.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-28T01:00:12.972459Z",
          "iopub.status.idle": "2024-11-28T01:00:12.972766Z",
          "shell.execute_reply": "2024-11-28T01:00:12.972634Z",
          "shell.execute_reply.started": "2024-11-28T01:00:12.972619Z"
        },
        "id": "OQNsCdiiU_TN"
      },
      "outputs": [],
      "source": [
        "idx = 23\n",
        "\n",
        "image_ds, caption_ds = train_ds.__getitem__(idx)\n",
        "# img_name = os.path.join(train_ds.image_folder, train_ds.file_name[idx])\n",
        "# image = Image.open(img_name).convert('RGBA')\n",
        "\n",
        "# import json\n",
        "# with open('/kaggle/input/trocr-large-finetuned/pytorch/default/1/models/trocr-large-finetuned-math-captions/vocab.json', 'r') as file:\n",
        "#\t tokenizer_json = json.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-28T01:00:12.973854Z",
          "iopub.status.idle": "2024-11-28T01:00:12.974296Z",
          "shell.execute_reply": "2024-11-28T01:00:12.974102Z",
          "shell.execute_reply.started": "2024-11-28T01:00:12.974078Z"
        },
        "id": "coKBMqGfU_TN"
      },
      "outputs": [],
      "source": [
        "history = []; val_history = []; val_timesteps = []\n",
        "ema_loss = None; ema_alpha = 0.95\n",
        "scaler = torch.amp.GradScaler(enabled = True)\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "\twith tqdm(train_dl, desc=f\"Epoch {epoch + 1}/{NUM_EPOCHS}\") as pbar:\n",
        "\t\tfor batch, captions in pbar:\n",
        "\t\t\tpixel_values = batch[\"pixel_values\"]\n",
        "\n",
        "\t\t\toptimizer.zero_grad()\n",
        "\t\t\twith torch.autocast(device_type = \"cuda\", dtype = t.float16, enabled = True):\n",
        "\t\t\t\toutputs = model(pixel_values = pixel_values,\n",
        "\t\t\t\t\t\t\t\tlabels = captions)\n",
        "\t\t\t\tloss = outputs.loss\n",
        "\t\t\t\thistory.append(loss.item())\n",
        "\t\t\tscaler.scale(loss).backward()\n",
        "\t\t\tscaler.step(optimizer)\n",
        "\t\t\tscaler.update()\n",
        "\n",
        "\t\t\tif ema_loss is None: ema_loss = loss.item()\n",
        "\t\t\telse: ema_loss = ema_loss * ema_alpha + loss.item() * (1 - ema_alpha)\n",
        "\t\t\tpbar.set_postfix(loss=ema_loss)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-28T01:00:12.975982Z",
          "iopub.status.idle": "2024-11-28T01:00:12.976443Z",
          "shell.execute_reply": "2024-11-28T01:00:12.976216Z",
          "shell.execute_reply.started": "2024-11-28T01:00:12.976192Z"
        },
        "id": "0z0CjDu5U_TN"
      },
      "outputs": [],
      "source": [
        "idx = 1559\n",
        "image = Image.open(f\"/kaggle/input/latex-ocr/training-data/{idx}.jpg\").convert('RGB')\n",
        "\n",
        "from IPython.display import display, Math, Latex\n",
        "display(image)\n",
        "pixel_values = processor(images = image, return_tensors=\"pt\").pixel_values.to(device)\n",
        "out = model.generate(pixel_values, max_new_tokens = 256)\n",
        "print(\"Prediction:\")\n",
        "pred = processor.decode(out[0], skip_special_tokens=True).replace(\"\\\\ \", \"\\\\\")\n",
        "# print(pred)\n",
        "display(Math(pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-28T01:00:12.97766Z",
          "iopub.status.idle": "2024-11-28T01:00:12.977961Z",
          "shell.execute_reply": "2024-11-28T01:00:12.977834Z",
          "shell.execute_reply.started": "2024-11-28T01:00:12.977819Z"
        },
        "id": "rvZcbgsAU_TN"
      },
      "outputs": [],
      "source": [
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-28T01:00:12.979217Z",
          "iopub.status.idle": "2024-11-28T01:00:12.979554Z",
          "shell.execute_reply": "2024-11-28T01:00:12.979416Z",
          "shell.execute_reply.started": "2024-11-28T01:00:12.979396Z"
        },
        "id": "PZSIUeTrU_TO"
      },
      "outputs": [],
      "source": [
        "latex_data = r'\\frac{b_{1}^{2}\\frac{72^{2}+96+2_{1}}{c_{1}B_{1}+{t_{5}+b_{1}}}}{7\\sqrt{28x+t_{1}}'\n",
        "\n",
        "symbols = ['lim','sin','cos','tan']\n",
        "for sym in symbols:\n",
        "\tlatex_data = latex_data.replace(sym, f\"\\\\{sym}\")\n",
        "\n",
        "\n",
        "# latex_data = re.sub(r'\\b(sin|cos|tan|lim)\\b', r'\\\\\\1', latex_data)\n",
        "print(latex_data)\n",
        "display(Math(latex_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-28T01:00:12.980701Z",
          "iopub.status.idle": "2024-11-28T01:00:12.980969Z",
          "shell.execute_reply": "2024-11-28T01:00:12.980849Z",
          "shell.execute_reply.started": "2024-11-28T01:00:12.980836Z"
        },
        "id": "jDBhvz-BU_TO"
      },
      "outputs": [],
      "source": [
        "model.save_pretrained(\"models/trocr-large-finetuned-math-captions\")\n",
        "processor.save_pretrained(\"models/trocr-large-finetuned-math-captions\")\n",
        "# t.save(history, \"../models/trocr-large-finetuned-math-captions/history.pt\")\n",
        "# t.save(val_history, \"../models/trocr-large-finetuned-math-captions/val_history.pt\")\n",
        "# t.save(val_timesteps, \"../models/trocr-large-finetuned-math-captions/val_timesteps.pt\")"
      ]
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 6002753,
          "sourceId": 9795294,
          "sourceType": "datasetVersion"
        },
        {
          "modelId": 161792,
          "modelInstanceId": 148619,
          "sourceId": 174559,
          "sourceType": "modelInstanceVersion"
        }
      ],
      "dockerImageVersionId": 30787,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "ocr",
      "language": "python",
      "name": "ocr"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}